ğŸ¤– ACME RAG Chatbot â€“ Document Question Answering System

This project is an AI-powered Retrieval-Augmented Generation (RAG) chatbot that enables users to ask natural-language questions from a document and receive accurate, context-aware answers.

The system uses LangChain, Google Gemini, and ChromaDB to retrieve relevant document chunks and generate responses through a clean Streamlit interface.

ğŸš€ Features

ğŸ“„ Load and process text documents

âœ‚ï¸ Automatic text chunking for efficient retrieval

ğŸ§  Semantic embeddings using Gemini Embedding Model

ğŸ” Similarity-based retrieval using ChromaDB

ğŸ’¬ Context-aware answers powered by Gemini LLM

ğŸ¨ Interactive web UI built with Streamlit

ğŸ› ï¸ Tech Stack

Python

Streamlit

LangChain

Google Gemini (LLM + Embeddings)

ChromaDB

FAISS (CPU)

TextLoader & RecursiveCharacterTextSplitter

ğŸ“‚ Project Structure
â”œâ”€â”€ app.py                     # Main Streamlit application
â”œâ”€â”€ Company_sample.txt         # Sample document for querying
â”œâ”€â”€ RAG_Pipeline_Components.ipynb  # RAG pipeline experimentation notebook
â”œâ”€â”€ requirements.txt           # Project dependencies
â””â”€â”€ README.md

â–¶ï¸ How to Run Locally
pip install -r requirements.txt
streamlit run app.py


Make sure to provide your Google API key when prompted or set it as an environment variable.

ğŸ¯ Use Case

Company manuals & policies

Knowledge-base chatbots

Document-based Q&A systems

RAG learning & experimentation

ğŸ“Œ Learning Outcomes

Hands-on experience with RAG architecture

Understanding of vector databases

Practical use of LLMs in real-world applications

Building end-to-end AI applications with Streamlit
